{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVD 5. cvičení\n",
    "\n",
    "## 1. část - TF-IDF s word embeddingy\n",
    "\n",
    "V minulém cvičení bylo za úkol implementovat TF-IDF algoritmus nad datasetem z Kagglu. Dnešní cvičení je rozšířením této úlohy s použitím word embeddingů. Lze použít předtrénované GloVe embeddingy ze 3. cvičení, nebo si v případě zájmu můžete vyzkoušet práci s Word2Vec od Googlu (najdete [zde](https://code.google.com/archive/p/word2vec/)).\n",
    "\n",
    "Cvičení by mělo obsahovat následující části:\n",
    "- Načtení článků a embeddingů\n",
    "- Výpočet document vektorů pomocí TF-IDF a word embeddingů \n",
    "    - Pro výpočet TF-IDF využijte [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) z knihovny sklearn\n",
    "    - Vážený průměr GloVe / Word2Vec vektorů\n",
    "\n",
    "<center>\n",
    "$\n",
    "doc\\_vector = \\frac{1}{|d|} \\sum\\limits_{w \\in d} TF\\_IDF(w) glove(w)\n",
    "$\n",
    "</center>\n",
    "\n",
    "- Dotaz bude transformován stejně jako dokument\n",
    "\n",
    "- Výpočet relevance pomocí kosinové podobnosti\n",
    "<center>\n",
    "$\n",
    "score(q,d) = cos\\_sim(query\\_vector, doc\\_vector)\n",
    "$\n",
    "</center>\n",
    "\n",
    "### Načtení článků"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def load(inf):\n",
    "    cl = list()\n",
    "    titleId = dict()\n",
    "    textId = dict()\n",
    "    titlesList = list()\n",
    "    textsList = list()\n",
    "    count = 0\n",
    "    with open(inf,\"r\",encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for i,line in enumerate(reader):\n",
    "            cl.append(i)\n",
    "            count = i\n",
    "            titlesList.append(line[4])\n",
    "            textsList.append(line[5])\n",
    "            for word in line[4].split():\n",
    "                if not word in titleId:\n",
    "                    titleId[word] = [i]\n",
    "                else:\n",
    "                    titleId[word].append(i)\n",
    "            for word in line[5].split():\n",
    "                if not word in textId:\n",
    "                    textId[word] = [i]\n",
    "                else:\n",
    "                    textId[word].append(i)\n",
    "    return titleId,textId,count,titlesList,textsList\n",
    "_,_,count,titlesList,textsList = load(\"articlesLEMMA.csv\")\n",
    "#print(titleId['a'][:5],textId['a'][:100],count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Načtení embeddingů"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "VecFile = \"glove.6B.300d.txt\"\n",
    "vecSize = 300\n",
    "wordVec = list()\n",
    "vecVec = list()\n",
    "wordDict = dict()\n",
    "read = 0\n",
    "\n",
    "with open(VecFile,\"r\", encoding = \"utf-8\") as file:\n",
    "    if(read>0):\n",
    "        for i in range(read):\n",
    "            line  = file.readline()\n",
    "            line = line.strip().split(\" \")\n",
    "            wordVec.append(line[0])\n",
    "            wordDict[line[0]] = i\n",
    "            vecVec.append(np.array(line[1:]).astype(float))\n",
    "    else:\n",
    "        i = 0\n",
    "        for iline in file:\n",
    "            line = iline.strip().split(\" \")\n",
    "            wordVec.append(line[0])\n",
    "            wordDict[line[0]] = i\n",
    "            vecVec.append(np.array(line[1:]).astype(float))\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def dist(vecl,vecr):\n",
    "    vv = np.dot(vecl,vecr)\n",
    "    a = np.sqrt(np.sum(np.square(vecl)))\n",
    "    b = np.sqrt(np.sum(np.square(vecr)))\n",
    "    return (vv/(a*b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + Word2Vec a vytvoření doc vektorů"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['019' '10' '1000x' '101' '1700' '18' '2012' '2017' '2018' '30' '37' '73'\n",
      " '90' 'a3c' 'abdulla' 'about' 'achievement' 'activation' 'actor' 'adam']\n",
      "(337, 816)\n",
      "False\n",
      "(337, 16324)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "titlesVectorizer = TfidfVectorizer()\n",
    "titlesFeatures = titlesVectorizer.fit_transform(titlesList)\n",
    "print(titlesVectorizer.get_feature_names_out()[:20])\n",
    "print(titlesFeatures.shape)\n",
    "textVectorizer = TfidfVectorizer()\n",
    "textsFeatures = textVectorizer.fit_transform(textsList)\n",
    "print('a' in textVectorizer.get_feature_names_out())\n",
    "print(textsFeatures.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from os import path\n",
    "import csv\n",
    "lst = list(textVectorizer.get_feature_names_out())\n",
    "def doc_vector_text(docIndex):\n",
    "    vec = np.zeros((vecSize))\n",
    "    wordlist = textsList[docIndex].split(' ')\n",
    "    wordHist = dict()\n",
    "    for w in wordlist:\n",
    "        if w in wordHist:\n",
    "            wordHist[w]+=1\n",
    "        else:\n",
    "            wordHist[w] = 1\n",
    "    dicwordCount = len(wordlist)\n",
    "    for w in wordHist:\n",
    "        if w in lst:\n",
    "            indx = list(textVectorizer.get_feature_names_out()).index(w)\n",
    "            if w in wordDict:\n",
    "                vec+= vecVec[wordDict[w]] * textsFeatures[docIndex,indx]*wordHist[w]\n",
    "    return vec/dicwordCount\n",
    "titlelst = list(titlesVectorizer.get_feature_names_out())\n",
    "def doc_vector_title(docIndex):\n",
    "    vec = np.zeros((vecSize))\n",
    "    wordlist = titlesList[docIndex].split(' ')\n",
    "    wordHist = dict()\n",
    "    for w in wordlist:\n",
    "        if w in wordHist:\n",
    "            wordHist[w]+=1\n",
    "        else:\n",
    "            wordHist[w] = 1\n",
    "    dicwordCount = len(wordlist)\n",
    "    for w in wordHist:\n",
    "        if w in titlelst:\n",
    "            indx = list(titlesVectorizer.get_feature_names_out()).index(w)\n",
    "            if w in wordDict:\n",
    "                vec+= vecVec[wordDict[w]] * titlesFeatures[docIndex,indx]*wordHist[w]\n",
    "    return vec/dicwordCount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textDocVec = list()\n",
    "filestr = \"textsVec.csv\"\n",
    "if not path.exists(filestr):\n",
    "    bar = IntProgress(min=0, max=count)\n",
    "    display(bar)\n",
    "    with open(filestr,\"w\",newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        for i in range(count):\n",
    "            docvec_text = doc_vector_text(i)\n",
    "            textDocVec.append(docvec_text)\n",
    "            line = list(docvec_text)\n",
    "            writer.writerow(line)\n",
    "            bar.value+=1\n",
    "else:\n",
    "    print(\"file \\\"textsVec.csv\\\" already exists\")\n",
    "    with open(filestr,\"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for line in reader:\n",
    "            linef = [float(x) for x in line]\n",
    "            linenp = np.asarray(linef)\n",
    "            textDocVec.append(linenp)\n",
    "        if len(textDocVec) == count:\n",
    "            print(\"file \\\"textsVec.csv\\\" OK\")\n",
    "        else:\n",
    "            print(\"file \\\"textsVec.csv\\\" NOK!!!\")\n",
    "            print(\"len\",len(textDocVec))\n",
    "            bar = IntProgress(min=0, max=count)\n",
    "            bar.value=len(textDocVec)\n",
    "            display(bar)\n",
    "            with open(filestr,\"a\",newline=\"\") as file:\n",
    "                writer = csv.writer(file)\n",
    "                for i in range(len(textDocVec),count):\n",
    "                    docvec_text = doc_vector_text(i)\n",
    "                    textDocVec.append(docvec_text)\n",
    "                    line = list(docvec_text)\n",
    "                    writer.writerow(line)\n",
    "                    bar.value+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file \"titlesVec.csv\" already exists\n",
      "file \"titlesVec.csv\" OK\n"
     ]
    }
   ],
   "source": [
    "titleDocVec = list()\n",
    "if not path.exists(\"titlesVec.csv\"):\n",
    "    bar = IntProgress(min=0, max=count)\n",
    "    display(bar)\n",
    "    with open(\"titlesVec.csv\",\"w\",newline=\"\") as file2:\n",
    "        titlesWriter = csv.writer(file2)\n",
    "        for i in range(count):\n",
    "            docvec_titles = doc_vector_title(i)\n",
    "            titleDocVec.append(docvec_titles)\n",
    "            line_title = list(docvec_titles)\n",
    "            titlesWriter.writerow(line_title)\n",
    "            bar.value+=1\n",
    "else:\n",
    "    print(\"file \\\"titlesVec.csv\\\" already exists\")\n",
    "    with open(\"titlesVec.csv\",\"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for line in reader:\n",
    "            linef = [float(x) for x in line]\n",
    "            linenp = np.asarray(linef)\n",
    "            titleDocVec.append(linenp)\n",
    "        if len(titleDocVec) == count:\n",
    "            print(\"file \\\"titlesVec.csv\\\" OK\")\n",
    "        else:\n",
    "            print(\"file \\\"titlesVec.csv\\\" NOK!!!\")\n",
    "            print(\"len\",len(titleDocVec))\n",
    "            bar = IntProgress(min=0, max=count)\n",
    "            display(bar)\n",
    "            with open(\"titlesVec.csv\",\"w\",newline=\"\") as file2:\n",
    "                titlesWriter = csv.writer(file2)\n",
    "                for i in range(len(titleDocVec),count):\n",
    "                    docvec_titles = doc_vector_title(i)\n",
    "                    titleDocVec.append(docvec_titles)\n",
    "                    line_title = list(docvec_titles)\n",
    "                    titlesWriter.writerow(line_title)\n",
    "                    bar.value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformace dotazu a výpočet relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreText(q:str, d:int)->float:\n",
    "    if(d>=len(textDocVec)):\n",
    "        return 0\n",
    "    qvec = np.zeros((vecSize))\n",
    "    wordlist = q.split(' ')\n",
    "    dicwordCount = len(wordlist)\n",
    "    for w in wordlist:\n",
    "        if w in lst:\n",
    "            indx = list(textVectorizer.get_feature_names_out()).index(w)\n",
    "            if w in wordDict:\n",
    "                qvec+=vecVec[wordDict[w]] * textsFeatures[d,indx]\n",
    "    qvec = qvec/dicwordCount\n",
    "    return dist(textDocVec[d],qvec)\n",
    "\n",
    "def scoreTitle(q:str, d:int)->float:\n",
    "    if(d>=len(titleDocVec)):\n",
    "        return 0\n",
    "    qvec = np.zeros((vecSize))\n",
    "    wordlist = q.split(' ')\n",
    "    dicwordCount = len(wordlist)\n",
    "    for w in wordlist:\n",
    "        if w in titlelst:\n",
    "            indx = list(titlesVectorizer.get_feature_names_out()).index(w)\n",
    "            if w in wordDict:\n",
    "                qvec+=vecVec[wordDict[w]] * titlesFeatures[d,indx]\n",
    "    qvec = qvec/dicwordCount\n",
    "    return dist(titleDocVec[d],qvec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18832\\2238044595.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (vv/(a*b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Chatbots were the next big thing: what h ... : Oh, how the headlines blared:\n",
      "Chatbots w ... : nan\n",
      "1 Python for Data Science: 8 Concepts You  ... : If you’ve ever found yourself looking up ... : nan\n",
      "2 Automated Feature Engineering in Python  ... : Machine learning is increasingly moving  ... : nan\n",
      "6 An intro to Machine Learning for designe ... : There is an ongoing debate about whether ... : 0.5526526190915289\n",
      "7 The Big List of DS/ML Interview Resource ... : Data science interviews certainly aren’t ... : nan\n",
      "9 What I learned from interviewing at mult ... : Over the past 8 months, I’ve been interv ... : nan\n",
      "10 From Ballerina to AI Researcher: Part I  ... : Last year, I published the article “From ... : nan\n",
      "11 3 Ways to Apply Latent Semantic Analysis ... : Latent semantic analysis works on large- ... : nan\n",
      "14 Machine Learning is Fun! Part 3: Deep Le ... : Update: This article is part of a series ... : 0.7000479615271177\n",
      "15 Machine Learning is Fun! Part 4: Modern  ... : Update: This article is part of a series ... : 0.6806160236429272\n"
     ]
    }
   ],
   "source": [
    "def scoreDocTitle(q:str,d:int,alpha:float = 0.7):\n",
    "    docScore = alpha * scoreTitle(q,d)+ (1-alpha) * scoreText(q,d)\n",
    "    if docScore != docScore:\n",
    "        return 0\n",
    "    else:\n",
    "        return docScore\n",
    "tts = list()\n",
    "text = \"coursera vs udacity machine learning\"\n",
    "for i in range(count):\n",
    "    tts.append((i,scoreDocTitle(text,i)))\n",
    "tts.sort(key = lambda x: x[1],reverse=True)\n",
    "titles = list()\n",
    "texts = list()\n",
    "with open(\"articles.csv\",\"r\",encoding=\"utf-8\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        titles.append(line[4])\n",
    "        texts.append(line[5])\n",
    "\n",
    "for i in range(10):\n",
    "    print(tts[i][0],titles[tts[i][0]][:40],'... :',texts[tts[i][0]][:40],'... :',tts[i][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus - Našeptávání\n",
    "\n",
    "Bonusem dnešního cvičení je našeptávání pomocí rekurentních neuronových sítí. Úkolem je vytvořit jednoduchou rekurentní neuronovou síť, která bude generovat text (character-level přístup). \n",
    "\n",
    "Optimální je začít po dokončení cvičení k předmětu ANS, kde se tato úloha řeší. \n",
    "\n",
    "Dataset pro učení vaší neuronové sítě naleznete na stránkách [Yahoo research](https://webscope.sandbox.yahoo.com/catalog.php?datatype=l&guccounter=1), lze využít např. i větší [Kaggle dataset](https://www.kaggle.com/c/yandex-personalized-web-search-challenge/data) nebo vyhledat další dataset na [Google DatasetSearch](https://datasetsearch.research.google.com/).\n",
    "\n",
    "Vstupem bude rozepsaný dotaz a výstupem by měly být alespoň 3 dokončené dotazy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b1f2b33e866b0bf2409397e5f58ba9cdf170d3b7f64c8f359c79998e2f88ad4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
